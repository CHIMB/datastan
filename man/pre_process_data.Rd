% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_standardization_script.R
\name{pre_process_data}
\alias{pre_process_data}
\title{Pre Process Data}
\usage{
pre_process_data(
  source_data_frame,
  split_source_fields,
  db_conn,
  dataset_to_standardize,
  standardized_name_lookup_table,
  standardized_function_lookup_table,
  flag_lookup
)
}
\arguments{
\item{source_data_frame}{A source data frame, the chunk read and passed from the pre_process_chunks() function.}

\item{split_source_fields}{A vector of split source fields that have a standardizing module assigned to them in the metadata, grouped by those standardizing modules.}

\item{db_conn}{A database connection that is used in addition to the dataset_id, passed from the standardize_data() function. Is also used in the pre_process_data() function.}

\item{dataset_to_standardize}{A dataset_id found and passed from the standardize_data() function, is used to make various calls to the database connection argument to obtain information required to pre-process the data.}

\item{standardized_name_lookup_table}{A vector containing all standardized column names/destination fields for a standardizing module.}

\item{standardized_function_lookup_table}{A vector containing all standardizing module names, used by concatenating/pasting the name onto the prefix “pre_process_” which will automatically call the correct module.}

\item{flag_lookup}{A lookup table containing manually set or default values used by the flag script which will use the values of the flags to determine how to pre-process and output the health data.}
}
\value{
A cleaned/standardized version of the source_data_frame parameter.
}
\description{
The pre_process_data() function will take in a source data frame object, and
go step-by-step through each part of the pre-processing to turn each source
data set into a common normalized format.
}
\examples{
cleaned_df <- pre_process_data(df, source_fields, db, 1, name_lookup, function_lookup, flag_lookup)
}
